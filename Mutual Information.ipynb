{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load contractions model\n",
    "from pycontractions import Contractions\n",
    "\n",
    "cont = Contractions(api_key=\"glove-twitter-100\")\n",
    "cont.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = 'c3'\n",
    "file = 'Data/'+cluster_name+'.csv'\n",
    "df = pd.read_csv(file,sep=\",\")\n",
    "df = df.loc[df['rating'] != 'OTHER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_claim(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    translator = str.maketrans('’', \"'\", '')\n",
    "    sentence = sentence.translate(translator)\n",
    "    sentence = re.sub(\"u\\.s\\.\",\"united states\",sentence)\n",
    "    sentence = list(cont.expand_texts([sentence],precise=True))[0]\n",
    "    sentence = re.sub(\"[^a-zA-Z0-9_.’,]|(?<!\\d)\\.(?!\\d)|(?<!\\w)-(?!\\w)|(?<!\\d)\\,(?!\\d)\",' ',sentence)\n",
    "    sentence = re.sub(\",\",'',sentence)\n",
    "    sentence = re.sub(\"\\.\",'',sentence)\n",
    "    sentence = re.sub(\" a \",' ',sentence)\n",
    "    sentence = re.sub('\\s+', ' ', sentence).strip()\n",
    "    sentence = re.sub(\" s \",' ',sentence)\n",
    "    if sentence[0:5] == 'says ':\n",
    "        sentence = sentence[5:]\n",
    "    sentence = ' '.join([w for w in sentence.split() if len(w)>1])\n",
    "    return sentence\n",
    "\n",
    "def preprocess_df(df):\n",
    "    for index in df.index:\n",
    "        df.at[index,'text'] = preprocess_claim(df.at[index,'text'])\n",
    "        rating = df.at[index,'rating']\n",
    "        if rating == 'FALSE':\n",
    "            df.at[index,'rating'] = 0\n",
    "        if rating == 'TRUE':\n",
    "            df.at[index,'rating'] = 1\n",
    "        if rating == 'MIXTURE':\n",
    "            df.at[index,'rating'] = 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information HMIN232M Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mi_dict(ngram,mindf,c,df):\n",
    "    #Get features\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram,min_df=mindf)\n",
    "    vectorizer.fit(df['text'])\n",
    "    \n",
    "    #Get A,B,C dicts\n",
    "    A_dict = {key:0 for key in vectorizer.get_feature_names()}\n",
    "    B_dict = {key:0 for key in vectorizer.get_feature_names()}\n",
    "    C_dict = {key:0 for key in vectorizer.get_feature_names()}\n",
    "    for key in vectorizer.get_feature_names():\n",
    "        for i in df.index:\n",
    "            claim = df.at[i,'text']\n",
    "            rating = df.at[i,'rating']\n",
    "            claim = ' ' + claim + ' '\n",
    "            if claim.find(' ' + key + ' ') >= 0:\n",
    "                if rating == c:\n",
    "                    A_dict[key] = A_dict[key] + 1\n",
    "                    continue\n",
    "                B_dict[key] = B_dict[key] + 1\n",
    "                continue\n",
    "            if rating == c:\n",
    "                C_dict[key] = C_dict[key] + 1\n",
    "                \n",
    "    #Get MI dict\n",
    "    MI_dict = dict()\n",
    "    for key in vectorizer.get_feature_names():\n",
    "        if A_dict[key] > 0:\n",
    "            MI_dict[key] = math.log10((A_dict[key] * df.shape[0]) / ((A_dict[key] + C_dict[key]) * (A_dict[key] + B_dict[key])))\n",
    "        else:\n",
    "            MI_dict[key] = 0\n",
    "    \n",
    "    #Sort and return MI dict\n",
    "    sorted_dict = sorted(MI_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mi_dict_sklearn(ngram,mindf,df,tfidf=False):\n",
    "    if tfidf == False:\n",
    "        vectorizer = CountVectorizer(ngram_range=ngram,min_df=mindf)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram,min_df=mindf)\n",
    "    X = vectorizer.fit_transform(df['text']).toarray()\n",
    "    y = df['rating']\n",
    "    features = vectorizer.get_feature_names()\n",
    "\n",
    "    mi_dict = dict()\n",
    "    for i in range(len(features)):\n",
    "        mi_dict[features[i]] = metrics.mutual_info_score(X[:,i],y)\n",
    "    \n",
    "    sorted_dict = sorted(mi_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mi(filename,mi,n):\n",
    "    rows = list()\n",
    "    header = [\"feature\",\"mi_score\"]\n",
    "    rows.append(header)\n",
    "\n",
    "    for i in range(n):\n",
    "        feature = mi[i][0]\n",
    "        score = mi[i][1]\n",
    "        row = [feature, score]\n",
    "        rows.append(row)    \n",
    "\n",
    "    with open('Data/'+filename,'w',newline='',encoding=\"utf-8\") as writeFile:\n",
    "        writer = csv.writer(writeFile,delimiter=';')\n",
    "        writer.writerows(rows)\n",
    "        writeFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = (1,3)\n",
    "mindf = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = list()\n",
    "\n",
    "for c in range(len(df['rating'].unique())):\n",
    "  mi.append(get_mi_dict(ngram,mindf,c,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mi)):\n",
    "    suffix = '_mi_class_%d.csv' % i\n",
    "    filename = cluster_name + suffix\n",
    "    save_mi(filename,mi[i],500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = get_mi_dict_sklearn(ngram,mindf,df,tfidf=False)\n",
    "\n",
    "suffix = '_mi_tf_sklearn.csv'\n",
    "filename = cluster_name + suffix\n",
    "save_mi(filename,mi,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = get_mi_dict_sklearn(ngram,mindf,df,tfidf=True)\n",
    "\n",
    "suffix = '_mi_tfidf_sklearn.csv'\n",
    "filename = cluster_name + suffix\n",
    "save_mi(filename,mi,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MI Authors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read authors\n",
    "authors_dict = dict()\n",
    "\n",
    "with open('Data/authors_classified.csv', 'r', newline='', encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row.\n",
    "    for row in reader:\n",
    "        authors_dict[row[0]] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unclassified rows\n",
    "ix=[i for i in df.index if ((df.at[i,'author'] in authors_dict.keys()))]\n",
    "df = df.loc[ix]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_type_columns(df):\n",
    "    df['person'] = 0\n",
    "    df['democrat'] = 0\n",
    "    df['republican'] = 0\n",
    "    df['political'] = 0\n",
    "    df['journalist'] = 0\n",
    "    df['organization'] = 0\n",
    "    for i in df.index:\n",
    "        author_type = authors_dict[df.at[i,'author']]\n",
    "        if author_type == 'Person':\n",
    "            df.at[i,'person'] = 1\n",
    "        if author_type == 'Democrat':\n",
    "            df.at[i,'person'] = 1\n",
    "            df.at[i,'democrat'] = 1\n",
    "        if author_type == 'Republican':\n",
    "            df.at[i,'person'] = 1\n",
    "            df.at[i,'republican'] = 1\n",
    "        if author_type == 'Political':\n",
    "            df.at[i,'person'] = 1\n",
    "            df.at[i,'political'] = 1\n",
    "        if author_type == 'Journalist':\n",
    "            df.at[i,'person'] = 1\n",
    "            df.at[i,'journalist'] = 1\n",
    "        if author_type == 'Organization':\n",
    "            df.at[i,'organization'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_type_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sklearn MI\n",
    "mi = dict()\n",
    "mi['person'] = metrics.mutual_info_score(df['person'].to_numpy(), df['rating'].to_numpy())\n",
    "mi['democrat'] = metrics.mutual_info_score(df['democrat'].to_numpy(), df['rating'].to_numpy())\n",
    "mi['republican'] = metrics.mutual_info_score(df['republican'].to_numpy(), df['rating'].to_numpy())\n",
    "mi['political'] = metrics.mutual_info_score(df['political'].to_numpy(), df['rating'].to_numpy())\n",
    "mi['journalist'] = metrics.mutual_info_score(df['journalist'].to_numpy(), df['rating'].to_numpy())\n",
    "mi['organization'] = metrics.mutual_info_score(df['organization'].to_numpy(), df['rating'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_author_mi(filename,mi):\n",
    "    rows = list()\n",
    "    header = [\"feature\",\"mi_score\"]\n",
    "    rows.append(header)\n",
    "\n",
    "    for key in mi:\n",
    "        feature = key\n",
    "        score = mi[key]\n",
    "        row = [feature, score]\n",
    "        rows.append(row)    \n",
    "\n",
    "    with open('Data/'+filename,'w',newline='',encoding=\"utf-8\") as writeFile:\n",
    "        writer = csv.writer(writeFile,delimiter=';')\n",
    "        writer.writerows(rows)\n",
    "        writeFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = '_mi_author_sklearn.csv'\n",
    "filename = cluster_name + suffix\n",
    "save_author_mi(filename,mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information HMIN232M Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mi(c,x,y):\n",
    "    A = 0\n",
    "    B = 0\n",
    "    C = 0\n",
    "    \n",
    "    m = len(x)\n",
    "    \n",
    "    for i in range(m):\n",
    "        if x[i] == 1:\n",
    "            if y[i] == c:\n",
    "                A = A + 1\n",
    "                continue\n",
    "            B = B + 1\n",
    "            continue\n",
    "        if y[i] == c:\n",
    "            C = C + 1\n",
    "    if A > 0:\n",
    "        mi = math.log10((A * m) / ((A + C) * (A + B)))\n",
    "    else:\n",
    "        mi = 0\n",
    "    \n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_list = list()\n",
    "\n",
    "for c in range(len(df['rating'].unique())):\n",
    "    mi = dict()\n",
    "    mi['person'] = get_mi(c,df['person'].to_numpy(), df['rating'].to_numpy())\n",
    "    mi['democrat'] = get_mi(c,df['democrat'].to_numpy(), df['rating'].to_numpy())\n",
    "    mi['republican'] = get_mi(c,df['republican'].to_numpy(), df['rating'].to_numpy())\n",
    "    mi['political'] = get_mi(c,df['political'].to_numpy(), df['rating'].to_numpy())\n",
    "    mi['journalist'] = get_mi(c,df['journalist'].to_numpy(), df['rating'].to_numpy())\n",
    "    mi['organization'] = get_mi(c,df['organization'].to_numpy(), df['rating'].to_numpy())\n",
    "    mi_list.append(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mi_list)):\n",
    "    suffix = '_mi_author_class_%d.csv' % i\n",
    "    filename = cluster_name + suffix\n",
    "    save_author_mi(filename,mi_list[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
