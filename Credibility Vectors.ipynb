{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load contractions model\n",
    "from pycontractions import Contractions\n",
    "\n",
    "cont = Contractions(api_key=\"glove-twitter-100\")\n",
    "cont.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = 'c1'\n",
    "file = 'Data/'+cluster_name+'.csv'\n",
    "df = pd.read_csv(file,sep=\",\")\n",
    "df = df.loc[df['rating'] != 'OTHER']\n",
    "df = df.loc[df['organization'] != 'snopes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_claim(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    translator = str.maketrans('’', \"'\", '')\n",
    "    sentence = sentence.translate(translator)\n",
    "    sentence = re.sub(\"u\\.s\\.\",\"united states\",sentence)\n",
    "    sentence = list(cont.expand_texts([sentence],precise=True))[0]\n",
    "    sentence = re.sub(\"[^a-zA-Z0-9_.’,]|(?<!\\d)\\.(?!\\d)|(?<!\\w)-(?!\\w)|(?<!\\d)\\,(?!\\d)\",' ',sentence)\n",
    "    sentence = re.sub(\",\",'',sentence)\n",
    "    sentence = re.sub(\"\\.\",'',sentence)\n",
    "    sentence = re.sub(\" a \",' ',sentence)\n",
    "    sentence = re.sub('\\s+', ' ', sentence).strip()\n",
    "    sentence = re.sub(\" s \",' ',sentence)\n",
    "    if sentence[0:5] == 'says ':\n",
    "        sentence = sentence[5:]\n",
    "    sentence = ' '.join([w for w in sentence.split() if len(w)>1])\n",
    "    return sentence\n",
    "\n",
    "def preprocess_df(df):\n",
    "    for index in df.index:\n",
    "        df.at[index,'text'] = preprocess_claim(df.at[index,'text'])\n",
    "        rating = df.at[index,'rating']\n",
    "        if rating == 'FALSE':\n",
    "            df.at[index,'rating'] = 0\n",
    "        if rating == 'TRUE':\n",
    "            df.at[index,'rating'] = 1\n",
    "        if rating == 'MIXTURE':\n",
    "            df.at[index,'rating'] = 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add authors to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read authors\n",
    "authors_dict = dict()\n",
    "\n",
    "with open('Data/authors_classified.csv', 'r', newline='', encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row.\n",
    "    for row in reader:\n",
    "        authors_dict[row[0]] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unclassified rows\n",
    "ix=[i for i in df.index if ((df.at[i,'author'] in authors_dict.keys()))]\n",
    "df = df.loc[ix]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_type_columns(df):\n",
    "    df['person'] = 0\n",
    "    df['democrat'] = 0\n",
    "    df['republican'] = 0\n",
    "    df['political'] = 0\n",
    "    df['journalist'] = 0\n",
    "    df['organization'] = 0\n",
    "    for i in df.index:\n",
    "        author_type = authors_dict[df.at[i,'author']]\n",
    "        if author_type == 'Person':\n",
    "            df.at[i,'person'] = 1\n",
    "        if author_type == 'Democrat':\n",
    "            df.at[i,'democrat'] = 1\n",
    "        if author_type == 'Republican':\n",
    "            df.at[i,'republican'] = 1\n",
    "        if author_type == 'Political':\n",
    "            df.at[i,'political'] = 1\n",
    "        if author_type == 'Journalist':\n",
    "            df.at[i,'journalist'] = 1\n",
    "        if author_type == 'Organization':\n",
    "            df.at[i,'organization'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_type_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get credibility vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vectors\n",
    "columns = ['person','democrat','republican','political','journalist','organization']\n",
    "ratings = sorted(df['rating'].unique())\n",
    "\n",
    "cred_vectors = {key:{rating:0 for rating in ratings} for key in columns}\n",
    "\n",
    "for i in df.index:\n",
    "    for column in columns:\n",
    "        if df.at[i, column] == 1:\n",
    "            cred_vectors[column][df.at[i, 'rating']] = cred_vectors[column][df.at[i, 'rating']] + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize vectors\n",
    "norm_cred_vectors = dict()\n",
    "\n",
    "for key in cred_vectors:\n",
    "    norm_cred_vectors[key] = dict()\n",
    "    total = sum(cred_vectors[key].values()) + len(cred_vectors[key])\n",
    "    for rating in cred_vectors[key]:\n",
    "        norm_cred_vectors[key][rating] = (cred_vectors[key][rating] + 1) / total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df, cred_vectors, columns):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram,min_df=mindf)\n",
    "    X = vectorizer.fit_transform(df['text']).toarray()\n",
    "    df_vectors = pd.DataFrame(X, columns = vectorizer.get_feature_names())\n",
    "    \n",
    "    for column in columns:\n",
    "        df_vectors[column] = 0\n",
    "    \n",
    "    for key in cred_vectors[columns[0]]:\n",
    "        df_vectors[key] = 0.0\n",
    "    \n",
    "    for i in df.index:\n",
    "        for column in columns:\n",
    "            if df.at[i,column] == 1:\n",
    "                df_vectors.at[i,column] = 1\n",
    "                for key in cred_vectors[column]:\n",
    "                    df_vectors.at[i,key] = cred_vectors[column][key]             \n",
    "    return df_vectors.to_numpy()\n",
    "    #return df_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = (1,3)\n",
    "mindf = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(df,cred_vectors,columns,key):\n",
    "    X = vectorize(df,cred_vectors,columns)\n",
    "    y = df[\"rating\"]\n",
    "    y = y.astype('int')\n",
    "    clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=None)\n",
    "    score = cross_val_score(clf, X, y, cv=k_fold, scoring='accuracy')\n",
    "    print('%s - Mean accuracy: %f, Deviation: %f' % (('%s with authors'%key),score.mean(),score.std()))\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Classes with authors - Mean accuracy: 0.554184, Deviation: 0.044829\n",
      "3 Classes with authors - Mean accuracy: 0.538721, Deviation: 0.035836\n",
      "3 Classes with authors - Mean accuracy: 0.556608, Deviation: 0.065547\n",
      "3 Classes with authors - Mean accuracy: 0.543598, Deviation: 0.037549\n",
      "3 Classes with authors - Mean accuracy: 0.545848, Deviation: 0.016044\n",
      "3 Classes with authors - Mean accuracy: 0.560295, Deviation: 0.036710\n",
      "3 Classes with authors - Mean accuracy: 0.540970, Deviation: 0.045749\n",
      "3 Classes with authors - Mean accuracy: 0.537345, Deviation: 0.042215\n",
      "3 Classes with authors - Mean accuracy: 0.555448, Deviation: 0.048902\n",
      "3 Classes with authors - Mean accuracy: 0.534987, Deviation: 0.036606\n",
      "Average of 10 runs: 0.546800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "\n",
    "scores = list()\n",
    "for i in range(iterations):\n",
    "    scores.append(classify(df,norm_cred_vectors,columns,'3 Classes'))\n",
    "\n",
    "avg = sum(scores)/len(scores)\n",
    "print(\"Average of %d runs: %f\\n\" % (iterations,avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cred vectors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize2(df, cred_vectors, columns):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram,min_df=mindf)\n",
    "    X = vectorizer.fit_transform(df['text']).toarray()\n",
    "    df_vectors = pd.DataFrame(X, columns = vectorizer.get_feature_names())\n",
    "    \n",
    "    for column in columns:\n",
    "        df_vectors[column] = 0\n",
    "    \n",
    "    for key in cred_vectors[columns[0]]:\n",
    "        df_vectors[key] = 0.0\n",
    "    \n",
    "    for i in df.index:\n",
    "        for column in columns:\n",
    "            if df.at[i,column] == 1:\n",
    "                df_vectors.at[i,column] = 1\n",
    "                for key in cred_vectors[column]:\n",
    "                    df_vectors.at[i,key] = cred_vectors[column][key]\n",
    "    \n",
    "    columns2 = columns.copy()\n",
    "    columns2.append(0)\n",
    "    columns2.append(1)\n",
    "    columns2.append(2)\n",
    "    df2 = df_vectors[columns2].copy()\n",
    "    return df2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify2(df,cred_vectors,columns,key):\n",
    "    X = vectorize2(df,cred_vectors,columns)\n",
    "    y = df[\"rating\"]\n",
    "    y = y.astype('int')\n",
    "    clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=None)\n",
    "    score = cross_val_score(clf, X, y, cv=k_fold, scoring='accuracy')\n",
    "    print('%s - Mean accuracy: %f, Deviation: %f' % (('%s with authors'%key),score.mean(),score.std()))\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Classes with authors - Mean accuracy: 0.583248, Deviation: 0.011876\n",
      "3 Classes with authors - Mean accuracy: 0.583190, Deviation: 0.010137\n",
      "3 Classes with authors - Mean accuracy: 0.578284, Deviation: 0.011880\n",
      "3 Classes with authors - Mean accuracy: 0.583234, Deviation: 0.012309\n",
      "3 Classes with authors - Mean accuracy: 0.583248, Deviation: 0.013015\n",
      "3 Classes with authors - Mean accuracy: 0.583190, Deviation: 0.006579\n",
      "3 Classes with authors - Mean accuracy: 0.583234, Deviation: 0.012309\n",
      "3 Classes with authors - Mean accuracy: 0.583219, Deviation: 0.011569\n",
      "3 Classes with authors - Mean accuracy: 0.583205, Deviation: 0.010925\n",
      "3 Classes with authors - Mean accuracy: 0.583176, Deviation: 0.009130\n",
      "Average of 10 runs: 0.582723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "\n",
    "scores = list()\n",
    "for i in range(iterations):\n",
    "    scores.append(classify2(df,norm_cred_vectors,columns,'3 Classes'))\n",
    "\n",
    "avg = sum(scores)/len(scores)\n",
    "print(\"Average of %d runs: %f\\n\" % (iterations,avg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
